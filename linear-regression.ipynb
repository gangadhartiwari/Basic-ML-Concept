{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":204267,"sourceType":"datasetVersion","datasetId":88705}],"dockerImageVersionId":30120,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 📈 **Linear Regression**","metadata":{}},{"cell_type":"markdown","source":"**In Machine Learning and this notebook we use Scikit-learn a lot.**\n\n<a href=\"https://uupload.ir/\" target=\"_blank\"><img src=\"https://s4.uupload.ir/files/download_(1)_slz6.png\" border=\"0\" alt=\"آپلود عکس\" /></a>\n\n### **What is scikit-learn used for?**\n\nScikit-learn (Sklearn) is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python.","metadata":{}},{"cell_type":"markdown","source":"#### **What is linear regression used for?**\n\nLinear regression analysis is used to predict the value of a variable based on the value of another variable. The variable you want to predict is called the dependent variable. The variable you are using to predict the other variable's value is called the independent variable.","metadata":{}},{"cell_type":"markdown","source":"# **Making Predictions with Linear Regression**\n\nGiven the representation is a linear equation, making predictions is as simple as solving the equation for a specific set of inputs.\n\nLet’s make this concrete with an example. Imagine we are predicting weight (y) from height (x). Our linear regression model representation for this problem would be:\n\n**y = B0 + B1 * x1**\n\nor\n\n**weight =B0 +B1 * height**\n\nWhere B0 is the bias coefficient and B1 is the coefficient for the height column. We use a learning technique to find a good set of coefficient values. Once found, we can plug in different height values to predict the weight.\n\nFor example, lets use B0 = 0.1 and B1 = 0.5. Let’s plug them in and calculate the weight (in kilograms) for a person with the height of 182 centimeters.\n\nweight = 0.1 + 0.5 * 182\n\nweight = 91.1\n\nYou can see that the above equation could be plotted as a line in two-dimensions. The B0 is our starting point regardless of what height we have. We can run through a bunch of heights from 100 to 250 centimeters and plug them to the equation and get weight values, creating our line.","metadata":{}},{"cell_type":"markdown","source":"<a href=\"https://uupload.ir/\" target=\"_blank\"><img src=\"https://s4.uupload.ir/files/sample-height-vs-weight-linear-regression_10h7.png\" border=\"0\" alt=\"آپلود عکس\" /></a>","metadata":{}},{"cell_type":"markdown","source":"Now that we know how to make predictions given a learned linear regression model, let’s look at some rules of thumb for preparing our data to make the most of this type of model.","metadata":{}},{"cell_type":"markdown","source":"# 📤 Import & Install Libraries","metadata":{}},{"cell_type":"code","source":"!pip install hvplot","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-12T06:16:32.547755Z","iopub.execute_input":"2022-02-12T06:16:32.548213Z","iopub.status.idle":"2022-02-12T06:16:41.837029Z","shell.execute_reply.started":"2022-02-12T06:16:32.548098Z","shell.execute_reply":"2022-02-12T06:16:41.836041Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport hvplot.pandas\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics\n\nfrom sklearn.linear_model import LinearRegression\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-12T06:16:41.838545Z","iopub.execute_input":"2022-02-12T06:16:41.838838Z","iopub.status.idle":"2022-02-12T06:16:45.462385Z","shell.execute_reply.started":"2022-02-12T06:16:41.838805Z","shell.execute_reply":"2022-02-12T06:16:45.461308Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 💾 Check out the Data","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/real-estate-price-prediction/Real estate.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:16:45.464442Z","iopub.execute_input":"2022-02-12T06:16:45.464764Z","iopub.status.idle":"2022-02-12T06:16:45.484555Z","shell.execute_reply.started":"2022-02-12T06:16:45.464729Z","shell.execute_reply":"2022-02-12T06:16:45.483626Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:16:45.487621Z","iopub.execute_input":"2022-02-12T06:16:45.488145Z","iopub.status.idle":"2022-02-12T06:16:45.520562Z","shell.execute_reply.started":"2022-02-12T06:16:45.48811Z","shell.execute_reply":"2022-02-12T06:16:45.51979Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:16:45.521902Z","iopub.execute_input":"2022-02-12T06:16:45.52255Z","iopub.status.idle":"2022-02-12T06:16:45.529966Z","shell.execute_reply.started":"2022-02-12T06:16:45.522501Z","shell.execute_reply":"2022-02-12T06:16:45.528795Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:16:45.531731Z","iopub.execute_input":"2022-02-12T06:16:45.532491Z","iopub.status.idle":"2022-02-12T06:16:45.556282Z","shell.execute_reply.started":"2022-02-12T06:16:45.532453Z","shell.execute_reply":"2022-02-12T06:16:45.555176Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.corr()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:16:45.557667Z","iopub.execute_input":"2022-02-12T06:16:45.557966Z","iopub.status.idle":"2022-02-12T06:16:45.581314Z","shell.execute_reply.started":"2022-02-12T06:16:45.557937Z","shell.execute_reply":"2022-02-12T06:16:45.580238Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.heatmap(df.corr(), annot=True,cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:16:45.582354Z","iopub.execute_input":"2022-02-12T06:16:45.582748Z","iopub.status.idle":"2022-02-12T06:16:46.391368Z","shell.execute_reply.started":"2022-02-12T06:16:45.582719Z","shell.execute_reply":"2022-02-12T06:16:46.390228Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 📊 Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:16:46.394021Z","iopub.execute_input":"2022-02-12T06:16:46.394354Z","iopub.status.idle":"2022-02-12T06:17:00.018258Z","shell.execute_reply.started":"2022-02-12T06:16:46.394321Z","shell.execute_reply":"2022-02-12T06:17:00.017434Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 📈 Training a Linear Regression Model\n\n## X and y arrays","metadata":{}},{"cell_type":"code","source":"X=df.drop('Y house price of unit area', axis=1)\n\ny=df['X4 number of convenience stores']","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.019818Z","iopub.execute_input":"2022-02-12T06:17:00.020126Z","iopub.status.idle":"2022-02-12T06:17:00.026593Z","shell.execute_reply.started":"2022-02-12T06:17:00.020094Z","shell.execute_reply":"2022-02-12T06:17:00.024995Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"X=\",X.shape,\"\\ny=\", y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.027899Z","iopub.execute_input":"2022-02-12T06:17:00.028261Z","iopub.status.idle":"2022-02-12T06:17:00.054438Z","shell.execute_reply.started":"2022-02-12T06:17:00.028189Z","shell.execute_reply":"2022-02-12T06:17:00.053206Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🧱 Train Test Split\n\nNow let's split the data into a training set and a testing set. We will train out model on the training set and then use the test set to evaluate the model.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.057023Z","iopub.execute_input":"2022-02-12T06:17:00.057398Z","iopub.status.idle":"2022-02-12T06:17:00.066186Z","shell.execute_reply.started":"2022-02-12T06:17:00.057356Z","shell.execute_reply":"2022-02-12T06:17:00.065276Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.068345Z","iopub.execute_input":"2022-02-12T06:17:00.068839Z","iopub.status.idle":"2022-02-12T06:17:00.079497Z","shell.execute_reply.started":"2022-02-12T06:17:00.068791Z","shell.execute_reply":"2022-02-12T06:17:00.078497Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.081119Z","iopub.execute_input":"2022-02-12T06:17:00.081767Z","iopub.status.idle":"2022-02-12T06:17:00.091656Z","shell.execute_reply.started":"2022-02-12T06:17:00.08172Z","shell.execute_reply":"2022-02-12T06:17:00.090117Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ✔️ Linear Regression","metadata":{}},{"cell_type":"code","source":"model = LinearRegression()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.092948Z","iopub.execute_input":"2022-02-12T06:17:00.093433Z","iopub.status.idle":"2022-02-12T06:17:00.102321Z","shell.execute_reply.started":"2022-02-12T06:17:00.0934Z","shell.execute_reply":"2022-02-12T06:17:00.10137Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.103754Z","iopub.execute_input":"2022-02-12T06:17:00.104039Z","iopub.status.idle":"2022-02-12T06:17:00.287372Z","shell.execute_reply.started":"2022-02-12T06:17:00.104012Z","shell.execute_reply":"2022-02-12T06:17:00.286482Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ✔️ Model Evaluation","metadata":{}},{"cell_type":"code","source":"model.coef_","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.288542Z","iopub.execute_input":"2022-02-12T06:17:00.288837Z","iopub.status.idle":"2022-02-12T06:17:00.295441Z","shell.execute_reply.started":"2022-02-12T06:17:00.288801Z","shell.execute_reply":"2022-02-12T06:17:00.294314Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(model.coef_, X.columns, columns=['Coedicients'])","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.296911Z","iopub.execute_input":"2022-02-12T06:17:00.297331Z","iopub.status.idle":"2022-02-12T06:17:00.312666Z","shell.execute_reply.started":"2022-02-12T06:17:00.297291Z","shell.execute_reply":"2022-02-12T06:17:00.311796Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ✔️ Predictions from our Model","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.314029Z","iopub.execute_input":"2022-02-12T06:17:00.314522Z","iopub.status.idle":"2022-02-12T06:17:00.327735Z","shell.execute_reply.started":"2022-02-12T06:17:00.314489Z","shell.execute_reply":"2022-02-12T06:17:00.326738Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ✔️ Regression Evaluation Metrics\n\n\nHere are three common evaluation metrics for regression problems:\n\n> - **Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n\n> - **Mean Squared Error** (MSE) is the mean of the squared errors:\n$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n\n> - **Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n\n> 📌 Comparing these metrics:\n- **MAE** is the easiest to understand, because it's the average error.\n- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n\n> All of these are **loss functions**, because we want to minimize them.","metadata":{}},{"cell_type":"code","source":"MAE= metrics.mean_absolute_error(y_test, y_pred)\nMSE=metrics.mean_squared_error(y_test, y_pred)\nRMSE= np.sqrt(MSE)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.329059Z","iopub.execute_input":"2022-02-12T06:17:00.329397Z","iopub.status.idle":"2022-02-12T06:17:00.33994Z","shell.execute_reply.started":"2022-02-12T06:17:00.329368Z","shell.execute_reply":"2022-02-12T06:17:00.33911Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAE","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.341019Z","iopub.execute_input":"2022-02-12T06:17:00.341497Z","iopub.status.idle":"2022-02-12T06:17:00.3535Z","shell.execute_reply.started":"2022-02-12T06:17:00.341467Z","shell.execute_reply":"2022-02-12T06:17:00.352515Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MSE","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.354848Z","iopub.execute_input":"2022-02-12T06:17:00.355169Z","iopub.status.idle":"2022-02-12T06:17:00.365271Z","shell.execute_reply.started":"2022-02-12T06:17:00.355128Z","shell.execute_reply":"2022-02-12T06:17:00.364402Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"RMSE","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.366552Z","iopub.execute_input":"2022-02-12T06:17:00.367023Z","iopub.status.idle":"2022-02-12T06:17:00.376773Z","shell.execute_reply.started":"2022-02-12T06:17:00.366992Z","shell.execute_reply":"2022-02-12T06:17:00.375979Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['X4 number of convenience stores'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.378023Z","iopub.execute_input":"2022-02-12T06:17:00.37854Z","iopub.status.idle":"2022-02-12T06:17:00.389503Z","shell.execute_reply.started":"2022-02-12T06:17:00.378497Z","shell.execute_reply":"2022-02-12T06:17:00.388681Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Residual Histogram**\n\n* **Often for Linear Regression it is a good idea to separately evaluate residuals $$(y-\\hat{y})$$ and not just calculate performance metrics (e.g. RMSE).**\n\n* **Let's explore why this is important...**\n\n* **The residual eerors should be random and close to a normal distribution.**\n\n\n<a href=\"https://uupload.ir/\" target=\"_blank\"><img src=\"https://s4.uupload.ir/files/download_ycg.png\" border=\"0\" alt=\"آپلود عکس\" /></a>\n\n<a href=\"https://uupload.ir/\" target=\"_blank\"><img src=\"https://s4.uupload.ir/files/2_pe68.png\" border=\"0\" alt=\"آپلود عکس\" /></a>","metadata":{}},{"cell_type":"code","source":"test_residual= y_test - y_pred","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.390813Z","iopub.execute_input":"2022-02-12T06:17:00.391346Z","iopub.status.idle":"2022-02-12T06:17:00.398893Z","shell.execute_reply.started":"2022-02-12T06:17:00.391314Z","shell.execute_reply":"2022-02-12T06:17:00.398131Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame({'Error Values': (test_residual)}).hvplot.kde()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.400121Z","iopub.execute_input":"2022-02-12T06:17:00.400609Z","iopub.status.idle":"2022-02-12T06:17:00.523372Z","shell.execute_reply.started":"2022-02-12T06:17:00.400577Z","shell.execute_reply":"2022-02-12T06:17:00.522388Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.displot(test_residual, bins=25, kde=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.526349Z","iopub.execute_input":"2022-02-12T06:17:00.526663Z","iopub.status.idle":"2022-02-12T06:17:00.904371Z","shell.execute_reply.started":"2022-02-12T06:17:00.526632Z","shell.execute_reply":"2022-02-12T06:17:00.903002Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Residual plot shows residual error VS. true y value.**","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=y_test, y=test_residual)\n\nplt.axhline(y=0, color='r', ls='--')","metadata":{"execution":{"iopub.status.busy":"2022-02-12T06:17:00.906059Z","iopub.execute_input":"2022-02-12T06:17:00.906727Z","iopub.status.idle":"2022-02-12T06:17:01.158875Z","shell.execute_reply.started":"2022-02-12T06:17:00.90668Z","shell.execute_reply":"2022-02-12T06:17:01.157632Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* **Residualplot showing a clear pattern, indicating Linear Regression no valid!**","metadata":{}},{"cell_type":"markdown","source":"# Finished, but you can copy this notebook and start practicing.","metadata":{}}]}